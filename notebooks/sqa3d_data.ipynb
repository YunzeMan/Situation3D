{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22d53cd1-5ede-4ae4-8ec6-c28aeb8f0663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preparing data...\n",
      "using 707 answers out of 707 ones\n",
      "all train: 26623\n",
      "answerable train 26623\n",
      "Tokenizing questions and situations using BERT Tokenizer...\n",
      "This may take a while...\n",
      "Finished tokenizing questions and situations using BERT Tokenizer\n",
      "loading data...\n",
      "using 707 answers out of 707 ones\n",
      "all val: 3519\n",
      "answerable val 3519\n",
      "Tokenizing questions and situations using BERT Tokenizer...\n",
      "This may take a while...\n",
      "Finished tokenizing questions and situations using BERT Tokenizer\n",
      "loading data...\n",
      "train on 26623 samples and val on 3519 samples\n",
      "\n",
      "======================\n",
      "This cell is finished.\n",
      "======================\n"
     ]
    }
   ],
   "source": [
    "# !module unload anaconda3_gpu/4.13.0\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import argparse\n",
    "import collections\n",
    "import numpy as np\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "sys.path.append('./Situation3D') \n",
    "from lib.sepdataset_bert import ScannetQADataset, ScannetQADatasetConfig\n",
    "from lib.config import CONF\n",
    "from models.sqa_module_bert import ScanQA\n",
    "# from scripts.train import get_sqa\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "# from tensorboardX import SummaryWriter\n",
    "# import wandb\n",
    "\n",
    "def get_sqa(sqa_train, sqa_val, train_num_scenes, val_num_scenes):\n",
    "    train_scene_list = sorted(list(set([data[\"scene_id\"] for data in sqa_train])))\n",
    "    val_scene_list = sorted(list(set([data[\"scene_id\"] for data in sqa_val])))\n",
    "    # set train_num_scenes\n",
    "    if train_num_scenes <= -1:\n",
    "        train_num_scenes = len(train_scene_list)\n",
    "    else:\n",
    "        assert len(train_scene_list) >= train_num_scenes\n",
    "\n",
    "    # slice train_scene_list\n",
    "    train_scene_list = train_scene_list[:train_num_scenes]\n",
    "\n",
    "    # filter data in chosen scenes\n",
    "    new_sqa_train = []\n",
    "    for data in sqa_train:\n",
    "        if data[\"scene_id\"] in train_scene_list:\n",
    "            new_sqa_train.append(data)\n",
    "\n",
    "    # set val_num_scenes\n",
    "    if val_num_scenes <= -1:\n",
    "        val_num_scenes = len(val_scene_list)\n",
    "    else:\n",
    "        assert len(val_scene_list) >= val_num_scenes\n",
    "\n",
    "    # slice val_scene_list\n",
    "    val_scene_list = val_scene_list[:val_num_scenes]\n",
    "\n",
    "    new_sqa_val = []\n",
    "    for data in sqa_val:\n",
    "        if data[\"scene_id\"] in val_scene_list:\n",
    "            new_sqa_val.append(data)\n",
    "\n",
    "    # all sqa scene\n",
    "    all_scene_list = train_scene_list + val_scene_list\n",
    "    return new_sqa_train, new_sqa_val, all_scene_list\n",
    "\n",
    "\n",
    "def get_answer_cands(answer_counter_list):\n",
    "    answer_counter = answer_counter_list\n",
    "    answer_counter = collections.Counter(sorted(answer_counter))\n",
    "    num_all_answers = len(answer_counter)\n",
    "    answer_max_size = -1\n",
    "    if answer_max_size < 0:\n",
    "        answer_max_size = len(answer_counter)\n",
    "    answer_counter = dict([x for x in answer_counter.most_common()[:answer_max_size] if x[1] >= 1])\n",
    "    print(\"using {} answers out of {} ones\".format(len(answer_counter), num_all_answers))\n",
    "    answer_cands = sorted(answer_counter.keys())\n",
    "    return answer_cands, answer_counter\n",
    "\n",
    "\n",
    "def get_dataloader(sqa, all_scene_list, split, config, augment, answer_counter_list):\n",
    "    answer_cands, answer_counter = get_answer_cands(answer_counter_list)\n",
    "    config.num_answers = len(answer_cands)\n",
    "    tokenizer = None\n",
    "\n",
    "    dataset = ScannetQADataset(\n",
    "        sqa=sqa[split],\n",
    "        sqa_all_scene=all_scene_list,\n",
    "        answer_cands=answer_cands,\n",
    "        answer_counter=answer_counter,\n",
    "        answer_cls_loss='bce',\n",
    "        split=split,\n",
    "        num_points=40000,\n",
    "        use_height=True,\n",
    "        use_color=True,\n",
    "        use_normal=False,\n",
    "        use_multiview=False,\n",
    "        tokenizer=tokenizer,\n",
    "        augment=augment,\n",
    "        debug=False,\n",
    "        wos=False,\n",
    "        use_bert=True,\n",
    "        no_mirror=True,\n",
    "        no_rotx=True,\n",
    "        no_roty=True\n",
    "    )\n",
    "    dataloader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "    return dataset, dataloader\n",
    "\n",
    "\n",
    "DC = ScannetQADatasetConfig()\n",
    "project_name = \"SQA\"\n",
    "SQA_TRAIN = json.load(open(os.path.join(CONF.PATH.SQA, project_name + \"_train.json\")))\n",
    "SQA_VAL = json.load(open(os.path.join(CONF.PATH.SQA, project_name + \"_test.json\")))\n",
    "answer_counter_list = json.load(open(os.path.join(CONF.PATH.SQA, \"answer_counter.json\")))\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "# init training dataset\n",
    "print(\"preparing data...\")\n",
    "sqa_train, sqa_val, all_scene_list = get_sqa(SQA_TRAIN, SQA_VAL, -1, -1)\n",
    "sqa = {\n",
    "    \"train\": sqa_train,\n",
    "    \"val\": sqa_val,\n",
    "}\n",
    "\n",
    "train_dataset, train_dataloader = get_dataloader(sqa, all_scene_list, \"train\", DC, True, answer_counter_list)\n",
    "val_dataset, val_dataloader = get_dataloader(sqa, all_scene_list, \"val\", DC, False, answer_counter_list)\n",
    "print(\"train on {} samples and val on {} samples\".format(len(train_dataset), len(val_dataset)))\n",
    "\n",
    "dataloader = {\n",
    "    \"train\": train_dataloader,\n",
    "    \"val\": val_dataloader\n",
    "}\n",
    "\n",
    "print('')\n",
    "print('======================')\n",
    "print('This cell is finished.')\n",
    "print('======================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "444723f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_batch = next(iter(dataloader['train']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "22616422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ['What', 'color', 'is', 'the', 'desk', 'to', 'my', 'right', '?'] ['I', 'am', 'facing', 'a', 'window', 'and', 'there', 'is', 'a', 'desk', 'on', 'my', 'right', 'and', 'a', 'chair', 'behind', 'me', '.']\n",
      "1 ['What', 'is', 'on', 'the', '12', \"o'clock\", 'of', 'the', 'coffee', 'table', 'that', 'is', 'on', 'my', '1', \"o'clock\", '?'] ['I', 'am', 'sitting', 'on', 'the', 'edge', 'of', 'the', 'couch', 'with', 'a', 'curtain', 'right', 'next', 'to', 'me', 'on', 'the', 'left', '.']\n",
      "5 ['What', 'object', 'to', 'my', '4', \"o'clock\", 'will', 'help', 'me', 'know', 'whether', 'I', 'am', 'running', 'late', 'to', 'class', '?'] ['I', 'am', 'facing', 'the', 'door', 'and', 'there', 'is', 'a', 'file', 'cabinet', 'on', 'my', 'left', '.']\n",
      "14 ['Which', 'object', 'is', 'better', 'to', 'sit', 'on', 'while', 'working', '-', 'the', 'couch', 'or', 'the', 'chair', 'on', 'my', 'left', '?'] ['I', 'am', 'sitting', 'on', 'the', 'left', 'cushion', 'of', 'a', 'couch', 'facing', 'a', 'cabinet', '.']\n",
      "106 ['Am', 'I', 'closer', 'to', 'the', 'plant', 'in', 'the', 'room', 'adjacent', 'to', 'the', 'room', 'I', 'im', 'in', 'or', 'the', 'desk', 'in', 'the', 'room', 'adjacent', 'to', 'the', 'room', 'I', 'am', 'in', '?'] ['I', 'am', 'sitting', 'on', 'a', 'chair', 'in', 'the', 'corner', 'facing', 'another', 'chair', 'at', 'the', 'desk', '.']\n",
      "10631 ['I', 'have', 'just', 'looked', 'at', 'myself', 'in', 'the', 'mirror', 'I', 'feel', 'that', 'I', 'have', 'checked', 'my', 'weight', 'effectively', '.', 'To', 'which', 'direction', 'should', 'I', 'move', 'to', 'weight', 'myself', 'and', 'see', 'if', 'there', 'are', 'improvements', 'in', 'terms', 'of', 'checking', 'my', 'weight', '?'] ['I', 'am', 'facing', 'a', 'sink', 'that', 'is', 'on', 'a', 'bathroom', 'vanity,', 'while', 'having', 'a', 'window', 'on', 'my', 'right', 'and', 'a', 'bathtub', 'directly', 'behind', 'me', '.']\n",
      "41\n",
      "0 ['I', 'am', 'facing', 'a', 'window', 'and', 'there', 'is', 'a', 'desk', 'on', 'my', 'right', 'and', 'a', 'chair', 'behind', 'me', '.'] ['What', 'color', 'is', 'the', 'desk', 'to', 'my', 'right', '?']\n",
      "1 ['I', 'am', 'sitting', 'on', 'the', 'edge', 'of', 'the', 'couch', 'with', 'a', 'curtain', 'right', 'next', 'to', 'me', 'on', 'the', 'left', '.'] ['What', 'is', 'on', 'the', '12', \"o'clock\", 'of', 'the', 'coffee', 'table', 'that', 'is', 'on', 'my', '1', \"o'clock\", '?']\n",
      "11 ['I', 'am', 'sitting', 'on', 'a', 'chair', 'which', 'is', 'very', 'close', 'to', 'the', 'window', 'and', 'I', 'am', 'facing', 'the', 'table', 'I', 'am', 'at', 'while', 'there', 'is', 'a', 'window', 'to', 'my', 'left', 'and', 'a', 'chair', 'on', 'the', 'same', 'side', 'of', 'the', 'table', 'with', 'me', 'to', 'my', 'right', 'within', 'reach', '.'] ['Is', 'the', 'door', 'in', 'front', 'of', 'me', 'or', 'behind', '?']\n",
      "26622 48\n"
     ]
    }
   ],
   "source": [
    "# print(sqa_train[0].get('question'))\n",
    "max_length = 0\n",
    "for x, record in enumerate(sqa_train[:]):\n",
    "    # show the record with the longest question list\n",
    "    if len(record.get('question')) > max_length:\n",
    "        max_length = len(record.get('question'))\n",
    "        print(x, record.get('question'), record.get('situation'))\n",
    "print(max_length)\n",
    "\n",
    "max_length = 0\n",
    "for x, record in enumerate(sqa_train[:]):\n",
    "    # show the record with the longest situation list\n",
    "    if len(record.get('situation')) > max_length:\n",
    "        max_length = len(record.get('situation'))\n",
    "        print(x, record.get('situation'), record.get('question'))\n",
    "print(x, max_length)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5fe222b-50c2-467a-aea6-c3ec9f45d7e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.1695787906646729, 0.03118199296295643, 1.5532602071762085, 0.0, 0.0, -0.03951023891568184, 0.9992191791534424]\n",
      "[0.009532594121992588, -2.462644100189209, 1.868485927581787, 0.0, 0.0, 0.999764621257782, -0.02169468253850937]\n",
      "[0.030481506139039993, -0.6087040305137634, 0.9354695677757263, 0.0, 0.0, -0.041241951286792755, 0.9991492033004761]\n",
      "[0.14939717948436737, -0.8001063466072083, 0.9635432362556458, 0.0, 0.0, 0.05638403072953224, 0.9984091520309448]\n",
      "[0.6156883835792542, -1.4739642143249512, 1.2038722038269043, 0.0, 0.0, -0.6923461556434631, 0.7215655446052551]\n",
      "\n",
      "======================\n",
      "This cell is finished.\n",
      "======================\n"
     ]
    }
   ],
   "source": [
    "train_scene_list = sorted(list(set([data[\"scene_id\"] for data in sqa_train])))\n",
    "val_scene_list = sorted(list(set([data[\"scene_id\"] for data in sqa_val])))\n",
    "scene_number_to_id = dataloader['val'].dataset.scene_number_to_id\n",
    "# print(val_scene_list)\n",
    "# print(first_batch['scene_id'][0])\n",
    "# print(scene_number_to_id[first_batch['scene_id'][0].item()])\n",
    "\n",
    "# print(len(train_scene_list), len(val_scene_list), len(all_scene_list)) # 518 67 585\n",
    "# print('Size of the dataset: ', len(sqa_train), '. Number of Iterations: ', len(dataloader['train'])) # 26623 832\n",
    "\n",
    "# print(sqa_train[0].keys()) # answers, object_ids, object_names, quesiton, situation, question_id, scene_id, position, original_question, original_situation\n",
    "# print(first_batch.keys()) # 's_feat', 'q_feat', 'point_clouds', 's_len', 'q_len', 'center_label', 'heading_class_label', 'heading_residual_label', 'size_class_label', 'size_residual_label', 'num_bbox', 'sem_cls_label', 'box_label_mask', 'vote_label', 'vote_label_mask', 'scan_idx', 'pcl_color', 'auxiliary_task', 'scene_id', 'question_id', 'load_time', 'answer_cat', 'answer_cats', 'answer_cat_scores', 'question_type', 'situation', 'question', 'answers'\n",
    "# print(first_batch['answers'][0][0])\n",
    "# print(first_batch['question_id'][0])\n",
    "# print(str(first_batch['question_id'][0].item()))\n",
    "# print(first_batch['auxiliary_task'][0].tolist())\n",
    "print(first_batch['auxiliary_task'][0].tolist())\n",
    "print(first_batch['auxiliary_task'][1].tolist())\n",
    "print(first_batch['auxiliary_task'][2].tolist())\n",
    "print(first_batch['auxiliary_task'][3].tolist())\n",
    "print(first_batch['auxiliary_task'][4].tolist())\n",
    "\n",
    "# # 's_feat', 'q_feat', 'point_clouds', 's_len', 'q_len', 'center_label', 'heading_class_label', 'heading_residual_label', 'size_class_label', 'size_residual_label', 'num_bbox', 'sem_cls_label', 'box_label_mask', 'vote_label', 'vote_label_mask', 'scan_idx', 'pcl_color', 'auxiliary_task', 'scene_id', 'question_id', 'load_time', 'answer_cat', 'answer_cats', 'answer_cat_scores'\n",
    "# print(first_batch['point_clouds'].shape) # torch.Size([32, 40000, 7])\n",
    "# print(first_batch['s_len'].shape, first_batch['q_len'].shape) # torch.Size([32])\n",
    "# print(first_batch['s_len']) \n",
    "# print(first_batch['center_label'].shape, first_batch['size_residual_label'].shape) # torch.Size([32, 128, 3])\n",
    "# print(first_batch['heading_class_label'].shape, first_batch['heading_residual_label'].shape, first_batch['size_class_label'].shape) # torch.Size([32, 128])\n",
    "# print(first_batch['num_bbox'].shape) # torch.Size([32])\n",
    "# print(first_batch['sem_cls_label'].shape, first_batch['box_label_mask'].shape) # torch.Size([32, 128])\n",
    "# print(first_batch['vote_label'].shape, first_batch['vote_label_mask'].shape) # torch.Size([32, 40000, 9]) torch.Size([32, 40000])\n",
    "# print(first_batch['scan_idx'].shape, first_batch['pcl_color'].shape) # torch.Size([32]) torch.Size([32, 40000, 3])\n",
    "# print(first_batch['auxiliary_task'].shape) # torch.Size([32, 7]) First 3 are position, next 4 are quaternion\n",
    "# print(first_batch['scene_id'].shape, first_batch['question_id'].shape) # torch.Size([32])\n",
    "# print(first_batch['load_time'].shape) # torch.Size([32])\n",
    "# print(first_batch['answer_cat'].shape, first_batch['answer_cats'].shape, first_batch['answer_cat_scores'].shape) # torch.Size([32]) torch.Size([32, 707]) torch.Size([32, 707])\n",
    "# print(first_batch['answer_cat'])\n",
    "\n",
    "print('')\n",
    "print('======================')\n",
    "print('This cell is finished.')\n",
    "print('======================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d14972a9-d4c1-4439-ba4b-b384c21d791e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "707\n",
      "[('under desk', 2), ('under table', 2), ('underneath', 2), ('untidy', 2), ('upstairs', 2), ('vacuum', 2), ('vertical', 2), ('walk backward', 2), ('walk to left', 2), ('warm', 2), ('water', 2), ('whiteboards', 2), ('whitec', 2), ('window sill', 2), ('windshield', 2), ('wine', 2), ('wood beam', 2), ('wood paneling', 2), ('wooden chairs', 2), ('yellow and orange', 2)]\n",
      "14715\n",
      "\n",
      "======================\n",
      "This cell is finished.\n",
      "======================\n"
     ]
    }
   ],
   "source": [
    "answer_counter = collections.Counter(sorted(answer_counter_list))\n",
    "num_all_answers = len(answer_counter)\n",
    "print(num_all_answers) # 707\n",
    "most_common = answer_counter.most_common()\n",
    "print(most_common[-20:])\n",
    "\n",
    "counter = 0\n",
    "for i in range(len(most_common))[14:]:\n",
    "    counter += most_common[i][1]\n",
    "print(counter) # 1000\n",
    "\n",
    "\n",
    "\n",
    "print('')\n",
    "print('======================')\n",
    "print('This cell is finished.')\n",
    "print('======================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "89aa64f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('What', 8171), ('Is', 5055), ('How', 4014), ('Can', 2520), ('Which', 2269), ('Are', 891), ('If', 801), ('Where', 645), ('Am', 415), ('I', 325), ('Does', 256), ('The', 187), ('To', 140), ('In', 120), ('Do', 80), (\"What's\", 74), ('On', 69), ('Would', 67), ('From', 63), ('When', 51), ('Turning', 47), ('Will', 42), ('Could', 34), ('There', 32), ('My', 19), ('Should', 18), ('Need', 17), ('Gotta', 16), ('Did', 15), ('Looking', 14), ('After', 11), ('Between', 9), ('Besides', 8), ('It', 7), ('Have', 7), ('Behind', 6), ('Has', 5), ('Wanna', 5), ('Someone', 5), ('Towards', 4), ('A', 3), ('Going', 3), ('Across', 3), (\"I've\", 3), ('Feeling', 3), ('While', 2), ('Cam', 2), ('Wat', 2), ('Im', 2), ('Apart', 2), ('Excluding', 2), ('Wanting', 2), ('Walking', 2), ('Of', 2), ('All', 2), ('Without', 2), ('As', 2), ('Other', 2), ('Suppose', 2), ('One', 2), ('Who', 1), ('Whats', 1), ('Now', 1), ('Towhat', 1), ('Total', 1), ('So', 1), ('Directly', 1), ('Why', 1), ('Want', 1), ('Whacolor', 1), ('Above', 1), ('⁴', 1), ('Whhat', 1), ('Getting', 1), ('Ebay', 1), ('Desks', 1), ('Its', 1), ('Whichdirection', 1), ('Class', 1), ('Were', 1), ('Trash', 1), ('Peeling', 1), ('Having', 1), ('Their', 1), ('Light', 1), ('Whcih', 1), ('Wgich', 1), ('Below', 1), ('Farther', 1), ('Some', 1), ('Oh', 1), ('Bathtub', 1), ('Here', 1), ('Iis', 1), ('Howe', 1), ('Whay', 1), ('Gotcha', 1), ('Standing', 1), ('Whehe', 1), ('Moving', 1), ('Oops!', 1), ('Under', 1), ('Radiator', 1), ('Cab', 1)]\n",
      "104\n",
      "If I get up and walk straight ahead, will I encounter an obstacle? ['yes']\n",
      "If I wanted to exit the room, what direction should I go? ['left']\n",
      "If I wanted to use stove, what direction should I go? ['forward']\n",
      "If I need to leave in case of fire, what direction should I go? ['right']\n",
      "If I wanted to use a table, what direction should I go? ['forward']\n",
      "If I wanted to use sink, what direction should I go? ['left']\n",
      "If I needed something in my luggage, which direction would I turn? ['right']\n",
      "If I want to send an email on my laptop, should I go left or rightwards? ['rightwards']\n",
      "If I turned left and walked straight, what would I hit? ['nightstand']\n",
      "If the amount of chairs in front of me even or odd? ['odd']\n",
      "If I wanted to have more light, what I turn on in front of my me? ['lamp']\n",
      "If I did a paper towel , which direction should I turn? ['right']\n",
      "If I wanted to leave the room, what direction should I go to leave the room? ['left']\n",
      "If I look forward what will I see above the bathroom vanity? ['mirror']\n",
      "If I want to shred some mail which way would I turn? ['left']\n",
      "If I wanted to look out the window, what direction should I go? ['forward']\n",
      "If there was a fire, what direction should I go to exit the room? ['right']\n",
      "If I look right at the second half of the room, could I feel like looking in the mirror? ['yes']\n",
      "If I fall off the table to my right what would. I crash through? ['window']\n",
      "If I go to a plant to my right, what will be directly on my way? ['armchair']\n",
      "I\n",
      "Does\n",
      "The\n",
      "To\n",
      "In\n",
      "Do\n",
      "What's\n",
      "On\n",
      "Would\n",
      "From\n",
      "When\n",
      "Turning\n",
      "Will\n",
      "Could\n",
      "There\n",
      "My\n",
      "Should\n",
      "Need\n",
      "Gotta\n",
      "Did\n",
      "Looking\n",
      "After\n",
      "Between\n",
      "Besides\n",
      "It\n",
      "Have\n",
      "Behind\n",
      "Has\n",
      "Wanna\n",
      "Someone\n",
      "Towards\n",
      "A\n",
      "Going\n",
      "Across\n",
      "I've\n",
      "Feeling\n",
      "While\n",
      "Cam\n",
      "Wat\n",
      "Im\n",
      "Apart\n",
      "Excluding\n",
      "Wanting\n",
      "Walking\n",
      "Of\n",
      "All\n",
      "Without\n",
      "As\n",
      "Other\n",
      "Suppose\n",
      "One\n",
      "Who\n",
      "Whats\n",
      "Now\n",
      "Towhat\n",
      "Total\n",
      "So\n",
      "Directly\n",
      "Why\n",
      "Want\n",
      "Whacolor\n",
      "Above\n",
      "⁴\n",
      "Whhat\n",
      "Getting\n",
      "Ebay\n",
      "Desks\n",
      "Its\n",
      "Whichdirection\n",
      "Class\n",
      "Were\n",
      "Trash\n",
      "Peeling\n",
      "Having\n",
      "Their\n",
      "Light\n",
      "Whcih\n",
      "Wgich\n",
      "Below\n",
      "Farther\n",
      "Some\n",
      "Oh\n",
      "Bathtub\n",
      "Here\n",
      "Iis\n",
      "Howe\n",
      "Whay\n",
      "Gotcha\n",
      "Standing\n",
      "Whehe\n",
      "Moving\n",
      "Oops!\n",
      "Under\n",
      "Radiator\n",
      "Cab\n",
      "1842\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "\n",
    "# SQA_TRAIN = json.load(open(os.path.join(CONF.PATH.SQA, project_name + \"_train.json\")))\n",
    "# print(SQA_TRAIN[0])\n",
    "# SQA_TRAIN[0]['original_question'] = 'Example question'\n",
    "# print(SQA_TRAIN[0]['question'])\n",
    "# SQA_TRAIN[0].update({'answers': [1]})\n",
    "# print(SQA_TRAIN[0])\n",
    "\n",
    "grouped = defaultdict(list)\n",
    "\n",
    "for record in SQA_TRAIN:\n",
    "    first_word = record['original_question'].split()[0]  # split the sentence into words and take the first one\n",
    "    grouped[first_word].append(record)\n",
    "\n",
    "# Count the number of sentences in each group\n",
    "counts = Counter({word: len(group) for word, group in grouped.items()}).most_common()\n",
    "print(counts)\n",
    "print(len(counts))\n",
    "\n",
    "question_type = counts[6][0]\n",
    "for i in range(len(grouped[question_type]))[:20]:\n",
    "    print(grouped[question_type][i]['original_question'], grouped[question_type][i]['answers'])\n",
    "\n",
    "counter = 0\n",
    "for i in range(len(counts))[9:]:\n",
    "    print(counts[i][0])\n",
    "    counter += counts[i][1]\n",
    "print(counter) # 1000\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c26ed977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all annotations:  ['answer_type', 'answers', 'position', 'question_id', 'question_type', 'rotation', 'scene_id']\n",
      "all data:  ['answers', 'object_ids', 'object_names', 'position', 'question', 'question_id', 'scene_id', 'situation']\n",
      "26623 26623\n",
      "{'x': -0.9651003385573296, 'y': -1.2417634435553606, 'z': 0} {'_x': 0, '_y': 0, '_z': 0.09983341664682724, '_w': 0.9950041652780182}\n",
      "[-0.9651003385573296, -1.2417634435553606, 0, 0, 0, 0.09983341664682724, 0.9950041652780182]\n"
     ]
    }
   ],
   "source": [
    "import json, sys\n",
    "import numpy as np\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "import argparse\n",
    "sys.path.append(os.path.join(os.getcwd(), 'lib')) # HACK add the lib folder\n",
    "from lib.config import CONF\n",
    "\n",
    "all_annotations = json.load(open(os.path.join('./dataset/sqa3d/SQA3D/assets/data/sqa_task/balanced', 'v1_balanced_sqa_annotations_train_scannetv2.json'), 'r'))['annotations'] # + \\\n",
    "    # json.load(open(os.path.join('./dataset/sqa3d/SQA3D/assets/data/sqa_task/balanced', 'v1_balanced_sqa_annotations_val_scannetv2.json'), 'r'))['annotations'] + \\\n",
    "    # json.load(open(os.path.join('./dataset/sqa3d/SQA3D/assets/data/sqa_task/balanced', 'v1_balanced_sqa_annotations_test_scannetv2.json'), 'r'))['annotations']\n",
    "\n",
    "all_data = \\\n",
    "    json.load(open(os.path.join('./dataset/sqa3d/SQA3D/ScanQA/data/qa', 'SQA_train.json'), 'r')) # + \\\n",
    "    # json.load(open(os.path.join('./dataset/sqa3d/SQA3D/ScanQA/data/qa', 'SQA_val.json'), 'r')) + \\\n",
    "    # json.load(open(os.path.join('./dataset/sqa3d/SQA3D/ScanQA/data/qa', 'SQA_test.json'), 'r'))\n",
    "\n",
    "\n",
    "qid2annoid = {}\n",
    "for i in range(len(all_annotations)):\n",
    "    qid2annoid[all_annotations[i][\"question_id\"]] = i\n",
    "\n",
    "print('all annotations: ', sorted(all_annotations[0].keys()))\n",
    "print('all data: ', sorted(all_data[0].keys()))\n",
    "print(len(all_annotations), len(all_data))\n",
    "print(all_annotations[0]['position'], all_annotations[0]['rotation'])\n",
    "print(all_data[0]['position'])\n",
    "\n",
    "# compare all_annotations and all_data to see if they are the same\n",
    "\n",
    "for i in range(len(all_data)):\n",
    "    question_id = all_data[i][\"question_id\"]\n",
    "    if all_data[i][\"answers\"][0] != all_annotations[qid2annoid[question_id]][\"answers\"][0]['answer'] and all_data[i][\"answers\"][0] != 'unknown':\n",
    "        print('answers mismatch: ', i, all_data[i][\"question\"], all_data[i][\"answers\"][0], all_annotations[qid2annoid[question_id]][\"answers\"][0]['answer'])\n",
    "    if all_data[i][\"scene_id\"] != all_annotations[qid2annoid[question_id]][\"scene_id\"]:\n",
    "        print('scene_id mismatch: ', i, all_data[i][\"scene_id\"], all_annotations[qid2annoid[question_id]][\"scene_id\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
